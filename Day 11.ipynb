{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c627a489-c588-4571-b34a-fcc0b07126ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **DAY 11 (19/01/26) â€“ Statistical Analysis & ML Prep**\n",
    "\n",
    "### Learn:\n",
    "\n",
    "- Descriptive statistics\n",
    "- Hypothesis testing\n",
    "- A/B test design\n",
    "- Feature engineering\n",
    "\n",
    "### ðŸ› ï¸ Tasks:\n",
    "\n",
    "1. Calculate statistical summaries\n",
    "2. Test hypotheses (weekday vs weekend)\n",
    "3. Identify correlations\n",
    "4. Engineer features for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbe2892f-b530-4b18-b90d-2f7621a57aa4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Oct = spark.read.csv('/Volumes/workspace/ecommerce/ecommerce_data/2019-Oct.csv',header=True,inferSchema=True)\n",
    "Nov = spark.read.csv('/Volumes/workspace/ecommerce/ecommerce_data/2019-Nov.csv',header=True,inferSchema=True)\n",
    "full_df = Oct.unionAll(Nov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bfc40a3-8d35-489f-abc2-3230e0125476",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "full_df = full_df.withColumn(\"event_date\",F.to_date('event_time'))\n",
    "full_df.repartition(500,'event_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "676dee06-29ac-461a-b762-5ba28ab3efbe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "silver = full_df.filter(F.col('price')>0)\\\n",
    "        .dropDuplicates(['user_session','event_time'])\\\n",
    "        .withColumn(\"price_tier\",\n",
    "                    F.when(F.col('price') <10,'Budget')\\\n",
    "                     .when(F.col('price') <50,'Mid')\\\n",
    "                     .otherwise('Premium'))\n",
    "silver.write.saveAsTable(\"ecommerce_full_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f0d9336-a710-4ba4-9a07-510408072ee7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "events = spark.sql('select * from ecommerce.default.ecommerce_full_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5f0642b-04f9-4386-98c3-55e13336f4a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "events.printSchema()\n",
    "events.limit(5).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43de6813-e64b-446e-8be4-b486703e4d18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Descriptive stats\n",
    "events.describe([\"price\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57179de5-e187-4a73-990a-02c4955c11b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Hypothesis: weekday vs weekend conversion\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "events_new=events.withColumn(\n",
    "    'is_weekend',\n",
    "    F.dayofweek('event_date').isin([1,7])\n",
    "    )\\\n",
    "    .groupBy('is_weekend',\"event_type\")\\\n",
    "    .count()\n",
    "events_new.show()\n",
    "# Conversion rate for weekend vs weekday\n",
    "events_conversion = events_new.groupBy('is_weekend').pivot('event_type').sum('count')\n",
    "events_conversion=events_conversion.withColumn('conversion_rate', (F.col('purchase')/F.col('view'))*100)\n",
    "events_conversion.show()\n",
    "\n",
    "weekend_rate = events_conversion.filter(F.col(\"is_weekend\") == True).select(\"conversion_rate\").first()[0]\n",
    "weekday_rate = events_conversion.filter(F.col(\"is_weekend\") == False).select(\"conversion_rate\").first()[0]\n",
    "\n",
    "# Compare\n",
    "if weekend_rate > weekday_rate:\n",
    "    print(\"Weekend conversion rate is higher than weekday\")\n",
    "else:\n",
    "    print(\"Weekday conversion rate is higher than weekend\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65ad3ee8-878a-4c49-a9d6-0960f4f2b5a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Correlation between price and conversion rate based on product id\n",
    "df_conversion=events.groupBy('product_id')\\\n",
    "    .agg(\n",
    "        F.avg('price').alias('avg_price'),\n",
    "        F.sum(F.when(F.col('event_type')=='view',1).otherwise(0)).alias('view'),\n",
    "        F.sum(F.when(F.col('event_type')=='purchase',1).otherwise(0)).alias('purchase')\n",
    "    )\\\n",
    "    .filter(F.col('view')>0)\\\n",
    "    .withColumn(\n",
    "        'conversion_rate',\n",
    "        (F.try_divide(F.col('purchase'), F.col('view')))*100\n",
    "    )\n",
    "\n",
    "result = df_conversion.corr(\"avg_price\", \"conversion_rate\")\n",
    "print(f'Correlation between avg_price and conversion rate',{result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c91be9c4-2cee-485d-8edd-6a53c60158e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "# Feature engineering\n",
    "features = events.filter(F.col('price')>0)\\\n",
    "    .withColumn(\"hour\", F.hour(\"event_time\")) \\\n",
    "    .withColumn(\"day_of_week\", F.dayofweek(\"event_date\")) \\\n",
    "    .withColumn(\"price_log\", F.log(F.col(\"price\")+1)) \\\n",
    "    .withColumn(\"time_since_first_view\",\n",
    "        F.unix_timestamp(\"event_time\").cast('long') -\n",
    "        F.first(\"event_time\").over(Window.partitionBy(\"user_id\").orderBy(\"event_time\")).cast('long'))\n",
    "features.limit(5).display()\n",
    "features.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "468eda22-1f74-4e7c-bbdb-d35ac002acdb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8131345940914319,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Day 11",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
